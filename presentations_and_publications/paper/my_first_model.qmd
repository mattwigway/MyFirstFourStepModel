---
title: "My First Four-Step Model: a Simple and Accessible Tool to Teach Travel Demand Modeling"
abstract: |
  Travel demand modeling is taught in most transportation engineering and planning programs. It is generally taught using a 'bottom-up' approach where students first learn about the theory and mathematics, and then work with individual model components. They may never run a complete travel demand model. I propose a 'top-down' approach where students first run a full demand model, focusing on outputs and the "big picture" of how the model works. This introduction provides students the tools to be critically engaged consumers of model output. Most students in planning and engineering will not become modelers, but many will work with model output.

  After a single lecture on demand modeling, I introduce a simple R package for running a four-step model on student's computers, and provide instructions for how to use it. Students have a homework assignment where they apply the model and interpret the outputs.   Students do well on the assignment, demonstrating an understanding of the basic structure of travel demand modeling. Most students take no additional modeling courses, but those that do have a strong foundation to build upon. Having students run a travel demand model soon after being introduced to the topic can help students focus on the big picture of modeling, and be informed consumers of model outputs, even if they take no further modeling classes.

keywords: [travel demand modeling, teaching, education, open-source]
bibliography: bibliography.bib
csl: apa.csl
authors:
  - name: Matthew Bhagat-Conway
    email: mwbc@unc.edu
    orcid: 0000-0002-1210-2982
    affiliations:
      - name: University of North Carolina at Chapel Hill
        department: Department of City and Regional Planning
format:
  pdf:
    documentclass: report
    geometry:
      - margin=1in
    mainfont: Times New Roman
    colorlinks: true
    template-partials:
      - before-body.tex
    include-in-header:
      text: |
        \usepackage{lineno}
        \usepackage{setspace}
date: 2025-08-06
#ntables: 3
execute:
    eval: true
    echo: true
    output: true
    cache: true
fig-dpi: 300
---
```{r}
#| include: false
library(tidyverse)
library(sf)
library(gridExtra)
library(gt)
```

## Practical applications

This article introduces a very simple travel demand modeling package, designed for use in educational settings. It runs on any modern consumer-grade computer, uses only free software, and provides forecasts for any region of the US. The goal of the tool is to give planners and engineers who do not work professionally with models enough experience to collaborate effectively with those who do. I describe how I use the tool in an introductory planning class, to give future planning practitioners experience with travel forecasting.

\newpage

## Introduction

Most transportation planning and engineering programs teach travel demand modeling to some extent [@zhou_transportation_2009]. In my experience, it is almost invariably taught with a 'bottom-up' approach. Students take classes on transportation planning, econometrics, and choice modeling. Students then work with individual components of demand models, such as trip generation or mode choice. Often, students never "put it all together" to run a regional model from start to finish. The vast majority of learning time is spent on theory and mathematics, rather than applications. In this article, I introduce a 'top-down' approach where running a complete model is one of the first steps, and discuss how I implement this in the classroom.

To facilitate teaching in this way, I introduce the open-source "My First Four-Step Model" R package, a simple four-step model that can install easily and run quickly on consumer-grade computers. It can be estimated for any US metropolitan area using publicly-available data. Complete code for running the model is presented in the results section.

Theory and mathematics are paramount for those who will build and run travel demand models themselves. This is a very small group of students, however. At most metropolitan planning organizations and DOT's, demand models are estimated and run by consultants or a small in-house team. Consumers of model output are a larger group: transportation planners and engineers, land use planners, developers, advocates, and so on. For this larger group, only a cursory understanding of the mathematics is required;  the general mechanisms and assumptions the model relies on are far more important. 

Most students in transportation planning and engineering programs will fall into the latter group. A better understanding of modeling among this group will help promote better communications between modelers and model consumers. Consumers will be more aware of what the model can and can't do, and more able to come up with situations where the model may be helpful. Understanding will also promote a "healthy skepticism" of the model, enabling feedback from users on the model and ultimately leading to better models and decision support.

Students interested in modeling may take further classes, but all students will have some first-hand experience with demand models---something many students do not get at all today, even after taking many classes on modeling.  I use this approach in my introductory Planning Methods course, where we spend only a week discussing transportation modeling and engineering, and at the conclusion the students run a simple demand model for the Research Triangle region of North Carolina. 

This article discusses the model structure and implementation and how I use it in the classroom, and includes R code to estimate and run a complete four-step model for anywhere in the US.

I am a planning faculty member, and draw on significant academic experience with modeling, theory, and mathematics, as well as a previous career as a software developer. I am a white male, a member of a group that is overrepresented in math and software development. I strive to make mathematics and modeling accessible to my students, who come from diverse backgrounds both socioeconomically and academically.

## Literature review

There is little literature on pedagogical practices surrounding travel demand modeling. Most transportation planning and engineering programs cover the topic [@zhou_transportation_2009], but it was not even included on a semi-regular survey of transportation faculty regarding what they consider the most important topics in introductory courses [@turochy_structuring_2013].

There is, however, a long history of pedagogy around teaching through simulating real-world activities undertaken by practitioners, rather than through one-to-many classroom instruction. This is most well established in the medical field, with positive outcomes for student learning [@mcgaghie_critical_2010]. Simulation activities are widely used in transportation engineering instruction [@hurwitz_transportation_2015], and research on active learning techniques in transportation engineering goes back decades [@weir_active_2004]. Simulation activities in planning have a similarly long history [e.g., @meier_gaming_1966].

Effective simulations as an educational tool often take the form of a game. Solving transportation challenges is one of the recurrent examples in the foundational book on gamification in education, Clark Abt's _Serious Games_ [@abt_serious_1970]. More recently, physical board games have been used to teach transportation planning using both popular-press games [@huang_game_2012] and purpose-built educational games [@paget-seekins_transform_2021].

Computer-based simulations have rapidly become ubiquitous in transportation engineering education [@hurwitz_transportation_2015]. Liao, Liu, and Levinson [-@liao_simulating_2009] built a web-based traffic simulation tool to help students experiment with signal timing practices. The interactive A/B Street traffic-simulation software has likewise been used in undergraduate courses at Arizona State University [@carlino_street_2024]. An economic simulation of airline operations has also been applied to help budding engineers understand airline operations [@luken_case_2011].

Computer-based simulations have also been applied in planning, although perhaps less frequently. Simulations in planning classrooms often take the form of commercial planning games, such as SimCity or Cities: Skylines [@gaber_simulating_2007;@khan_perceptions_2021], likely due to less funding for purpose-built simulations in planning as opposed to engineering. A significant challenge with commercial games is that they are intended primarily for entertainment, and thus may oversimplify or even modify system dynamics to support enjoyable gameplay rather than educational outcomes [@gaber_simulating_2007;@walker_did_2009]. The advantage is that commercial games are more likely to receive significant upfront investment as well as continued support, a significant problem with games developed for educational purposes [@sobke_two_2018].

Public education and communication are another arena of planning where gamification and simulation have been deployed. The _Future Energy Chicago_ exhibit at Chicago's Museum of Science and Industry engaged participants in a several-hour, facilitated game to improve energy outcomes. Survey data suggests that the game improved some aspects of willingness to conserve energy [@applebaum_collaboration_2021]. The CityScope platform provides a hands-on physical environment wherein members of the public can make land-use changes to a Lego model of a neighborhood and see computer simulation output regarding transport and energy consumption in real time [@alonso_cityscope_2018]. The CoAXs platform allows meeting participants to see how proposed Bus Rapid Transit routes would affect their ability and the ability of other citizens to reach key destinations, and was found to support improved learning and discussion outcomes among participants [@stewart_coaxs_2016;@stewart_mapping_2017]. All of these simulations are perforce somewhat simpler than might be used in a classroom environment, since they target the general public rather than future practitioners.

Teaching travel demand modeling differs from other places where simulations have been deployed in transportation education. Travel demand models are themselves simulations of complex urban systems. Applying them in a classroom environment does not demand developing a new simulation. Rather, it means simplifying the existing structure of demand models to create one suitable for students with only a rudimentary understanding of the theory and mathematics involved.

The only travel demand modeling software designed specifically for education I am aware of is the now-defunct Agent-Based Demand and Assignment Model (ADAM) software [@zhu_enhancing_2011]. ADAM implemented a simple agent-based model for transportation education. This model focused on a network assignment for simple networks; it started with production (workers) and attractions (jobs), and students modified the network to reduce congestion. Likely due to computational limits in place at the time, it worked with a very simple network of only 24 nodes and 68 links.

I focus on the ubiquitous four-step model in my introductory courses. The four-step model was one of the earliest travel demand models developed [@weiner_urban_2013;@federalhighwayadministration_planpac_1977]. While it has come under significant criticism lately [@mladenovic_shortcomings_2014], it remains in common use. Many large regions have transitioned to more modern activity-based models, but many smaller regions and even some large ones continue to use the four-step model.

## Pedagogical goals

My First Four-Step Model is a software package that allows students with minimal experience and consumer-grade computer hardware to run a simple four-step travel demand model. Specifically, it is designed to address these student learning outcomes:

\quad

1. Have a basic understanding of the structure and mathematics of travel demand model,
1. Understand the types of scenarios travel demand models are appropriate for,
1. Understand the limitations and uncertainty of travel demand modeling, and
1. Be able to have constructive conversations with travel modelers.

\quad

It is implemented as an R package [@r_2024], which has several advantages. R is a free, open-source, and cross-platform statistical programming language, allowing students to run it on their own computers regardless of configuration. Furthermore, R is becoming the _lingua franca_ of quantitative urban planning. Using the My First Four-Step Model package in an assignment gives students a gentle introduction to the language and potentially piques their interest in learning more. The package has several key design goals:

\quad

1. The four steps of the model map directly onto four functions in the package;
1. Any place where there is a tradeoff between simplicity and predictive accuracy, simplicity is chosen;
1. It can be estimated for any location in the United States using only publicly-available data;
1. There are intuitive tools to visualize model inputs, outputs, and parameters, so students can interpret and understand the model;
1. Preparing land-use and transportation scenarios is simple;
1. It runs on any computer a student is likely to have (including Windows, Macs, and Chromebooks); and
1. It depends only on R itself and common R packages that are easily installed from the Comprehensive R Archive Network (CRAN).

\quad

To meet these goals, the model is highly simplified, and this certainly affects its predictive accuracy, but predictive accuracy is not one of the goals. Epstein [-@epstein_why_2008] lists 16 reasons to build models other than prediction. One of them, train practitioners, is the primary goal of this model. This goal does not depend on high predictive accuracy.

The open-source package is available on Github at <https://github.com/mattwigway/MyFirstFourStepModel>.

## Results: implementation in the classroom

I use the package in my Planning Methods course in the Department of City and Regional Planning at the University of North Carolina at Chapel Hill. This is an introductory master's level course which all planning students (not only those in transportation) take, generally during their first semester. In the course, I spend a week discussing transportation planning and engineering. I give a single hour-and-fifteen-minute lecture on transportation modeling, covering primarily the four-step model, but with a nod to activity-based models. We discuss the general structure of the model. We cover some basic mathematical underpinnings of discrete-choice models. We discuss travel surveys and how they are used in model development.

I then have an assignment where all students run and interpret the output of a four-step model. Specifically, students first run a baseline model. They then change land use inputs to reflect Chatham Park, a large proposed housing development in Pittsboro, NC. Pittsboro is a town that is quickly becoming an exurb of the Research Triangle. I give students guidance on the number of households to add based on development plans, but give them discretion in determining the demographics of those households. They then run the model again. This portion of the assignment is worth five points plus 0.5 extra credit points for calculating statistical significance from a coefficient and standard error. For each step of the model, I have 1–2 homework questions. These questions cover interpretation the coefficients of the constituent models, and what the outputs indicate about the transportation system and differences between scenarios.

There is also an extra credit section worth two points where students run their scenario again with a network where 15-501, the main highway between Pittsboro and Chapel Hill, is widened from two to three lanes. I have them interpret how congestion changes in this scenario. Modeled results of widening projects are often overstated due to induced demand, the phenomenon where building more roadway capacity induces more people to take trips on that road. Like many four-step models, My First Four-Step Model does not account for induced demand. I have students discuss how this biases the results.

I provide the students with an R file, all of the code of which is included inline in this section to run the model. The full homework assignment is in the appendix.

Students do well on this assignment. In Spring 2025, the mean score was 5.96 (n=42, s.d.=1.51, median=5.5, 25th percentile=5, 75th percentile=7.45). 20 students (48%) attempted the two-point extra credit section looking at highway widening. Unfortunately, this class did not cover travel demand modeling prior to the introduction of My First Four-Step Model, so it is not possible to evaluate how the tool has changed learning outcomes.^[This use of student grade data was reviewed and approved by the University of North Carolina at Chapel Hill Registrar and Institutional Review Board (approval 24-2069). The requirement for consent was waived due to the aggregate nature of the data.]

The goal is to enable students in all specializations, not just transportation, to understand basic demand model structure and have productive conversations with modelers. For students who want to work more closely with models in their careers, I also teach a semester-long travel demand modeling course using a more complex model developed in TransCAD. Most transportation specialization students take this course later in their program.

### Installation

All my students already have R and RStudio installed on their machines from a previous exercise on linear regression. Installing My First Four-Step Model is simple; students run the following R code at the command prompt to install the package:

```{r}
#| eval: false
install.packages('MyFirstFourStepModel', repos = c('https://mattwigway.r-universe.dev', 'https://cloud.r-project.org'))

```

This installs a pre-compiled R package containing the model. It also automatically installs the R packages `MyFirstFourStepModel` depends on—notably `tidyverse` [@tidyverse], `sf` [@sf], `igraph` [@igraph], `readxl` and `writexl` [@readxl;@writexl], `tidycensus` [@tidycensus], `tigris` [@tigris], and `nnet` [@nnet].

### Loading the package and the model

Next, students load the `MyFirstFourStepModel` package, and an already-estimated model. Most model users will never estimate a model themselves, so I provide an already-estimated model for the Research Triangle region of North Carolina. The model can be read either from a local file or directly from an `https` URL. Reading directly from a URL requires the instructor to have access to a server, but avoids needing to troubleshoot local file paths. The URL included below is a live URL with the model for the Research Triangle.

```{r}
#| eval: false
library(MyFirstFourStepModel)
model = load_model("https://files.indicatrix.org/rdu_chatham.model")
```

```{r}
#| include: false
library(MyFirstFourStepModel)
model = load_model("https://files.indicatrix.org/rdu_chatham.model")
```

### Trip generation

The first step of the four-step process is trip generation. Trip generation is done at the household level using linear regression. I use linear regression rather than traditional cross-classification or more complex regression methods because of its ease of interpretation, and because I teach demand modeling shortly after teaching linear regression. Before running the trip generation model, I have students view the trip generation model for AM Peak home-based work trips, using the code below, and interpret the coefficients (@tbl-production).

```{r}
#| eval: false
summary(model$production_functions$`AM Peak`$HBW)
```

```{r}
#| echo: false
#| label: tbl-production
#| tbl-cap: Trip production regression for AM Peak home-based work trips
summary(model$production_functions$`AM Peak`$HBW)$coefficients |>
    as_tibble(rownames="Coefficient") |>
    mutate(Coefficient=case_match(Coefficient,
      "vehicles" ~ "Number of vehicles",
      "hhsize" ~ "Household size",
      "factor(income) 35000" ~ "Income 35,000-74,999",
      "factor(income) 75000" ~ "Income 75,000-99,999",
      "factor(income)100000" ~ "Income > 100,000",
      "HTRESDN" ~ "Housing unit density in home tract (units/square mile)",
      "workers" ~ "Number of workers",
      .default=Coefficient
    )) |>
    gt() |>
        fmt_number()
```

I similarly have them interpret one of the regressions for attraction functions (coefficients not shown for brevity):

```{r}
#| eval: false
summary(model$attraction_functions$`AM Peak`$HBW)
```

Once students have interpreted the regressions, I have them run the trip generation step. True to the design goals, this requires only a single function.

```{r}
productions_attractions = trip_generation(model, model$scenarios$baseline)
```

Students can then map the number of trips produced and attracted in each Census tract in the region using the `map_trip_generation` function as shown below ([@fig-generation]).

```{r}
#| eval: false
map_trip_generation(
  model,
  productions_attractions,
  "Productions",
  "AM Peak",
  "HBW"
)

map_trip_generation(
  model,
  productions_attractions,
  "Attractions",
  "AM Peak",
  "HBW"
)
```

```{r}
#| label: fig-generation
#| fig-cap: Home-based work trip productions and attractions for the Research Triangle region, AM Peak
#| fig-alt: AM Peak home-based work trip productions and attractions. Productions are spread across the region, whereas attractions are more concentrated.
#| echo: false
grid.arrange(
    map_trip_generation(model, productions_attractions, "Productions", "AM Peak", "HBW") +
        theme(legend.position="bottom", legend.text=element_text(angle=-45, hjust=0)),
    map_trip_generation(model, productions_attractions, "Attractions", "AM Peak", "HBW") +
        theme(legend.position="bottom", legend.text=element_text(angle=-45, hjust=0)),
    nrow=1,
    ncol=2
)
```

### Trip distribution

Trip distribution uses a simple gravity model, with different parameters estimated for home-based work, home-based other, and non-home-based trips. I first have students print the parameters using the code below, and interpret them (the estimated values for the Research Triangle region are -1.21 for home-based work trips, -1.87 for home-based other trips, and -1.71 for non-home-based trips).

```{r}
#| eval: false
model$distribution_betas
```

Then, they can run the trip distribution step with the following code

```{r}
flows = trip_distribution(
  model,
  model$scenarios$baseline,
  productions_attractions
)
```

Students can then map the trip distribution results for any origin Census tracts, and interpret them. @fig-distribution shows the results for AM Peak home-based work trips originating from a tract in suburban Durham; results show that many trips stay local, but there are also pockets of activity in further-flung large employment centers (e.g., Raleigh).

```{r}
#| label: fig-distribution
#| fig-alt: AM Peak trip distribution from a census tract in suburban Durham, NC; most trips go to nearby destinations, but some go to further-flung large employment centers near Raleigh
#| fig-cap: AM Peak trip distribution, from a selected tract in suburban Durham, NC
map_trip_distribution(
  model,
  flows,
  "AM Peak",
  "HBW",
  origin_tract="37063002025"
)

```

### Mode choice

The mode choice model is a multinomial logit model with four modes: walk, bike, transit, and drive. Since the model is estimated from public data, there are minimal attributes of each individual trip available, so the model is very simple and primarily based on Euclidean distance between the origin and destination. I give a very basic expanation of the multinomial logit model, highlighting  commonalities with linear regression, and have students print the mode choice model using the code below, and interpret a few coefficients  (@tbl-mc):

```{r}
#| eval: false
summary(model$mode_choice_models$HB)
```

\footnotesize
```{r}
#| echo: false
#| label: tbl-mc
#| tbl-cap: Coefficients from the multinomial logit mode choice model, for home-based trips
s = summary(model$mode_choice_models$HB)
cf = format(round(s$coefficients, 4), scientific=F)

colnames(cf) =  str_replace(colnames(cf), "factor\\(.*\\)", "")

t = s$coefficients / s$standard.errors
cf[abs(t) > 1.96] = paste0(cf[abs(t) > 1.96], "*")
cf[abs(t) <= 1.96] = paste0(cf[abs(t) <= 1.96], " ")

cf[abs(t) > 2.58] = paste0(cf[abs(t) > 2.58], "*")
cf[abs(t) <= 2.58] = paste0(cf[abs(t) <= 2.58], " ")

cf[abs(t) > 3.29] = paste0(cf[abs(t) > 3.29], "*")
cf[abs(t) <= 3.29] = paste0(cf[abs(t) <= 3.29], " ")

cf |>
    as_tibble(rownames="Mode") |>
    gt() |>
    cols_label(
      HTRESDN="Density",
      dist_km="Trip length (km)",
      HBW="Work trip"
    ) |>
    tab_source_note("* = p < 0.05, ** = p<0.01, ***=p < 0.001") |>
    tab_footnote("Homes/sq. mi. in home Census tract", cells_column_labels(3)) |>
    tab_options(table.font.size=10)
```

\normalsize

I then have students run the mode choice step and calculate mode shares, using the code below; for the Triangle region, they are 91% car, 5% walk, 3% transit, and 1% bike in the baseline.

```{r}
#| output: false
flows_by_mode = mode_choice(model, model$scenarios$baseline, flows)
get_mode_shares(flows_by_mode)
```


### Network assignment

The final step of the model is network assignment. A simple Frank-Wolfe static traffic assignment algorithm is used to assign trips to the network. Since network assignment is time consuming, a relatively simple network is used. The network used in the Research Triangle example model has 7529 nodes and 10497 edges. The code below performs assignment for the PM Peak and displays congestion (@fig-congestion). To maximize network assignment performance, a small amount of code written in the Rust language [@klabnickRustProgrammingLanguage2025] is used to efficiently process routing results; this code is pre-compiled and will be installed automatically when `MyFirstFourStepModel` is installed.

```{r}
#| eval: false
pm_network_flows = network_assignment(
  model,
  model$scenarios$baseline,
  model$networks$baseline,
  flows_by_mode,
  "PM Peak"
)
map_congestion(model, model$networks$baseline, pm_network_flows)
```

```{r}
#| echo: false
#| output: false
pm_network_flows = network_assignment(model, model$scenarios$baseline, model$networks$baseline, flows_by_mode, "PM Peak")
```

```{r}
#| echo: false
#| label: fig-congestion
#| fig-cap: Forecast PM Peak congestion
#| fig-alt: Map of forecast PM Peak congestion, with heavy congestion on some major routes and light congestion elsewhere.
map_congestion(model, model$networks$baseline, pm_network_flows)
```

Agencies are increasingly interested in vehicle miles traveled. The assignment step can also estimate VMT by period using the code below. For the PM Peak in the Research Triangle, this is estimated to be 7 million miles/day. The 2017 Local Area Transportation Characteristics for Households (LATCH) statistics estimate total VMT in the Triangle region to be 26 million miles/day [author calculations from @bureauoftransportationstatistics_2017_2024], so 7 million in the PM Peak is reasonable.

```{r}
estimate_vmt(model, model$networks$baseline, pm_network_flows, "PM Peak")
```

### Land-use scenarios

The code above runs a complete, simplified, four-step model for baseline conditions. However, we are generally interested in forecasts for future years under different scenarios. Above, I requested baseline land use by specifying `model$scenario$baseline`. The baseline is automatically created during model estimation based on Census population and employment data.

There are two ways to create additional scenarios. The simpler method is to use the `add_households` function. This function modifies a scenario by adding households with particular characteristics to a particular area. The code below adds 20,000 households to Census tract `37037020801`, which is the location of a large new residential development. The households to add are specified in a tabular format. In this case, are all four-person, two-worker households; half have three cars and income of $150,000/year, and half have two cars and income of $75,000/year.

```{r}
model$scenarios$future = model$scenarios$baseline |>
  add_households(
    "37037020801",
    tribble(
      ~hhsize, ~workers, ~vehicles, ~income, ~n,
      4,       2,        3,         150000,  10000,
      4,       2,        2,         75000,   10000
    )
  )
```

The model can then be re-run using the same steps as above, substituting `model$scenarios$future` for `model$scenarios$baseline`. This results in the forecast congestion shown in @fig-chatham. The new development is highlighted with a red dot.

```{r}
#| echo: false
#| output: false
#| include: false
cp_trips = trip_generation(model, model$scenarios$future)
cp_flows = trip_distribution(model, model$scenarios$future, cp_trips)
cp_modeflows = mode_choice(model, model$scenarios$future, cp_flows)
cp_pm_network_flows = network_assignment(model, model$scenarios$future, model$networks$baseline, cp_modeflows, "PM Peak")
```

```{r}
#| label: fig-chatham
#| fig-cap: Forecast congestion levels after adding 20,000 households, PM Peak
#| echo: false
map_congestion(model, model$networks$baseline, cp_pm_network_flows) +
  geom_sf(data=st_as_sf(
    tribble(
      ~lat, ~lon,
      35.7302, -79.1582
    ),
    coords=c("lon", "lat"),
    crs=4326
  ) |> st_transform(3857), aes(fill=NULL), color="red", size=4)
```

If more control is needed, scenarios can be created in a tabular format by hand or using external tools. This format is shown in @tbl-demographic-scenario, specifying the number of households in different household size, income, vehicle ownership, and number of worker categories. A similar format is used to specify employment numbers (used as a proxy for out-of-home destinations).

|  `geoid`      | `marginal` | `value` | `count` |
|:------------|:-------|--:|---:|
| 37183053411 | `hhsize` | 1 | 514 |
| 37183053411 | `hhsize` | 2 | 711 |
| 37183053411 | `hhsize` | 3 | 940 |
| 37183053411 | `hhsize` | 4 | 1907 |
| 37183053411 | `income` | 0 | 358 |
| 37183053411 | `income` | 35000 | 595 |
| 37183053411 | `income` | 75000 | 183 |
| 37183053411 | `income` | 100000 | 2936 |
| 37183053411 | `vehicles` | 0 | 110 |
| 37183053411 | `vehicles` | 1 | 921 |
| 37183053411 | `vehicles` | 2 | 2089 |
| 37183053411 | `vehicles` | 3 | 952 |
| 37183053411 | `workers` | 0 | 288 |
| 37183053411 | `workers` | 1 | 1784 |
| 37183053411 | `workers` | 2 | 1711 |
| 37183053411 | `workers` | 3 | 289 |

: Specification of a demographic scenario {#tbl-demographic-scenario}

In the assignment I give to my students, I use this format to create a scenario based on a demographic forecast we work earlier in the semester. To do this, I first export the baseline scenario into Excel format:

```{r}
#| eval: false
save_landuse_scenario(model$scenarios$baseline, "baseline.xlsx")
```

After modifying the scenario to be consistent with the forecast growth using external tools, I re-load it:

```{r}
#| eval: false
model$scenarios$projected = load_landuse_scenario("projected.xlsx")
```

### Network scenarios

Changes to the network are just as important as changes to land use. Currently, My First Four-Step Model only supports changes to existing links.

Two link attributes can be changed: the lane count and the roadway type. The roadway type uses OpenStreetMap highway tag taxonomy; notable values are 'motorway', 'trunk', and 'primary'. Changing the attributes of a link requires determining its OpenStreetMap 'way ID', which can be done either by looking at the data on [openstreetmap.org](https://openstreetmap.org), or exporting the network to GIS format and investigating in GIS:

```{r}
#| eval: false
network_to_gis(model$networks$baseline, "baseline.gpkg")
```

Link attributes can then be modified using the `modify_links` function. For example, the code below widens the road going north from the development, from two to three lanes in each direction, and upgrades it to a motorway. Some way IDs are suppressed for brevity (see Supplemetal Materials for full code).

```{r}
#| eval: false
model$networks$widen = model$networks$baseline |>
  modify_ways(
    # US 15-501 between Pittsboro and Chapel Hill
    c(
      "16468788", "133051274", "16471803", "285898984",
      . . .
      "712336821", "712336826", "712336827", "998595932"
    ),
    lanes_per_direction=3,
    highway_type="motorway"
  )
```

```{r}
#| include: false
model$networks$widen = model$networks$baseline |>
  modify_ways(
    # US 15-501 between Pittsboro and Chapel Hill
    c(
      "16468788", "133051274", "16471803", "285898984",
       "16476716", "822063218", "29335841", "709833467",
      "29335943", "29335943", "654023608", "654023604",
       "29336020", "29336065", "29336043",
      "29336065", "29336065", "1119560022", "29336065",
       "29336065", "690900371", "133051279", "29336072",
      "690900390", "29336325", "29336326", "29336327", 
      "29336328", "29336338", "29336335", "29336336",
      "116792787", "138138864", "29336430", "138138830",
       "116792819", "50370797", "50370799", "50370826",
      "50370836", "133051276", "133051275", "133051277",
       "133051276", "133051276", "133051278", "133051278",
      "1119560050", "690900383", "1028209511", "138138830",
       "138138830", "1064169631", "138138830", "138138830",
      "1064169646", "138138830", "285898976", "625793296",
       "285898977", "712336832", "654023612", "285898984",
      "285898984", "285898992", "694843964", "1064169630",
       "1064169647", "398223958", "712336806", "398223959",
      "712336808", "518951244", "709833464", "713044971", 
      "1265931335", "574612704", "614242454", "713044971",
      "614242450", "614242450", "614242453", "614242454", 
      "614242453", "690900386", "690900353", "690900357",
      "690900390", "694843965", "709833465", "709833466", 
      "998595933", "712336807", "712336820", "712336809",
      "712336821", "712336826", "712336827", "998595932"
    ),
    lanes_per_direction=3,
    highway_type="motorway"
  )
```

Students can then repeat the network assignment step with the new network to see how congestion changes—in this case, that there is no longer forecast congestion along the road we modified (@fig-widen). This also provides a jumping-off point to discuss the (lack of) modeling of induced demand.

```{r}
#| output: false
#| echo: false
#| include: false
cpw_pm_network_flows = network_assignment(model, model$scenarios$future, model$networks$widen, cp_modeflows, "PM Peak")
```

```{r}
#| label: fig-widen
#| fig-cap: Forecast congestion, PM Peak, with widened 15-501.
#| echo: false
map_congestion(model, model$networks$widen, cpw_pm_network_flows) +
  geom_sf(data=st_as_sf(
    tribble(
      ~lat, ~lon,
      35.7302, -79.1582
    ),
    coords=c("lon", "lat"),
    crs=4326
  ) |> st_transform(3857), aes(fill=NULL), color="red", size=4)
```

## Methods: estimation of a new model

Estimating a new model requires only a few lines of code, however it does require the 2017 National Household Travel Survey [NHTS, @NHTS_2017] and an OpenStreetMap PBF file for the region modeled.^[OpenStreetMap PBF files for any region are easily obtained from <https://slice.openstreetmap.us>] The code to estimate a model for the Research Triangle region is below. First, it loads the relevant libraries, and then the NHTS (`NHTS_PATH` should be replaced with a directory containing the NHTS CSV files). I filter the NHTS to only North Carolina households with a weekday travel day ($n=7,146$). The final line estimates the model. It requires the (possibly filtered) NHTS, the path to the OpenStreetMap data (written as `OSM_PATH` below but should be replaced with the actual path), the state and a vector of counties to define the region under study, and a year. Currently 2021 is most recent year available, as this is based on American Community Survey and Longitudinal Employer-Household Dynamics data availability.

Parsing the OpenStreetMap data uses Julia [@bezanson_julia_2017] for performance, which can be installed if it is not already by running `JuliaCall::install_julia()` from within R. Julia is only required for estimation; students do not need to install Julia.

```{r}
#| output: false
#| eval: false
library(MyFirstFourStepModel)
library(tidyverse)

# Load NHTS and filter to North Carolina weekday data
nhts = load_nhts(NHTS_PATH)
nhts$households = filter(
  nhts$households,
  HHSTATE == "NC" & TRAVDAY %in% c(2, 3, 4, 5, 6)
)

# Estimate the model using 2021 Census/LODES data for the Triangle
model = estimate(nhts, OSM_PATH, "NC", c("Durham", "Orange", "Wake", "Chatham"), 2021)
```

Lastly, the model can be saved to a file for distribution to students. 
```{r}
#| eval: false
save_model(model, "rdu.model")
```

This can be loaded by the `load_model` function described above, either from a file or a URL. If any land-use or network scenarios are created or loaded prior to saving the model, they will be included in the saved file.

## Model architecture and input data

### Trip generation

Trip generation is based on the NHTS. The model uses four time periods: overnight (7:00 pm--5:59 am), AM Peak (6:00 am--9:59 am), midday (10:00 am--3:59 pm), and PM Peak (4:00 pm--6:59 pm). The model divides trips into three purposes: home-based work (HBW), home-based other (HBO), and non-home-based (NHB). While this is fewer trip types and time periods than might be included in production travel models, it is consistent with the general practice of dividing trips by time of day and count.

Household-level trip counts are estimated for each time period and trip type using a simple linear regression with the trip count as the dependent variable and independent variables for number of vehicles, household size, household income, Census tract residential density, and number of workers. This results in 12 regression equations, for each time period and trip purpose. Household income is represented by dummy variables for less than $35,000, $35,000–$74,999, $75,000–$99,999, and $100,000 or more.

These regression models are disaggregate, household-level models, whereas the four-step model is an aggregate model using marginal data at the TAZ level (for simplicity, TAZs correspond directly to Census tracts). Specifically, the model uses household size (topcoded at 4), number of workers (topcoded at 3), number of vehicles (topcoded at 3), and income (in the categories used in the regression). To apply the household-level model to this aggregate data, I disaggregate the data to household-level records (i.e. create a synthetic population) using iterative proportional fitting with a seed matrix derived from the Integrated Public Use Microdata Sample 2021 Five-Year American Community Survey data for the entire US [@ruggles_ipums_2024]. This seed matrix ships with the software. The regressions predict household-level tripmaking, which is  re-aggregated to the tract level.

The NHTS does not provide sufficient spatial detail to estimate trip attractions. Instead, I use the Puget Sound Household Travel Survey, which includes origin and destination Census tract in the public-use dataset [@PSRC_Household_Travel_Survey]. I calculate the number of HBW and HBO trips in each time period that have the non-home end in each Census tract in the Puget Sound region. For NHB trips, the production and attraction ends are not clearly defined. I therefore assume that NHB attractions and productions are half of the total number of NHB trips originating from or destined to each tract.

To extrapolate this data to tracts outside the region, I build linear regression models for each trip type and time period based on total employment and employment in retail, education, and accomodation/food services from the US Census Bureau Longitudinal Employer-Household Dynamics Origin-Destination Employment Statistics. I balance total attractions by trip type in each time period to match estimated productions.

### Trip distribution

The trip distribution step uses a singly-constrained (at the production end) gravity model [@travelforecastingresource_destination_2020]. The exponent for the gravity model is calibrated for each trip type using the method introduced by Merlin [-@merlin_new_2020] based on median trip length. The method observes that half of the weighted destinations should be closer to the origin than the median trip, and half should be further away. I make two slight changes to the function presented in Merlin [-@merlin_new_2020]; see appendix.

The median trip distance comes from the NHTS. I approximate the crow-flies distance for each NHTS trip by dividing the network distance by 1.3, a factor determined by @wang_how_2024.

For intrazonal trips, I assume a travel distance of $0.52 \sqrt{s}$, where $s$ is the area of the TAZ. This is based on a Monte Carlo simulation of the average distance between random points in a square. There are two opposing factors that bias this. TAZ's are not square, increasing average travel distance. However, development within a TAZ is concentrated in certain areas, decreasing average travel distance. I assume these roughly cancel out.

### Mode choice

The mode choice model is a multinomial logit model based on the NHTS. Because there is not detailed information about each trip and the alternatives available in the NHTS, the model is based solely on trip type, time period, travel distance, and housing unit density in the home tract. For NHB trips, a separate model is estimated excluding density. Goodness of fit is poor, but the point of the model is to demonstrate a simple demand model, not to produce accurate forecasts.

### Network assignment

The network assignment uses a Frank-Wolfe traffic assignment algorithm [@blubook-vol1-v091]. First, I convert production-attraction format home-based trips into origin-destination format, using directionality factors estimated from the NHTS. I calculate peak hourly vehicle flows during each period using average vehicle occupancy for each period and trip type, and an assumed "peaking factor" that accounts for the proportion of traffic during the time period that occurs in the busiest hour—for example, I assume 45% of the traffic in the three-hour PM Peak period occurs during the busiest hour. Then, I run the assignment algorithm, with impedances based on a Bureau of Public Roads-style function:
$$
t_{\mathrm{congested}} = \left(1 + 0.6 \left[\frac{f}{c}\right] ^ 5 \right) t_{\mathrm{freeflow}} 
$$

where $f$ is the predicted flow, $c$ is the link capacity, and $t_{\mathrm{congested}}$ and $t_\mathrm{freeflow}$ are congested and free-flow link travel times. The factors 0.6 and 5 are from the Southern California Association of Governments travel demand model [@southerncaliforniaassociationofgovernments_scag_2012].

The assignment algorithm is written in pure R. This is quite slow, but will run anywhere R does without any installation complexity. To keep runtimes reasonable (on the order of minutes or tens of minutes, depending on the computer), networks need to be simple, and regions small. In the example, I use the central four counties of the Research Triangle region.

I derive the network from OpenStreetMap. By default, I retain only the most major roads—motorways, trunk, and primary roads (and associated ramps). Furthermore, I run the assignment algorithm only until the "relative gap"—a measure of the error in the estimate—is 1%, rather than the typically recommended 0.01% [@boyce_convergence_2004], to improve performance.

## Discussion and conclusion

This article introduced a new way of teaching travel demand modeling in introductory courses. The primary change is to move the step of working with an actual demand model _much_ earlier in the process, after only a few lectures. To facilitate this, I introduced the My First Four-Step Model R package, which implements a highly simplified demand model that can be run on students' machines and estimated anywhere in the US with only publicly-available data. With only a few lines of code, which I provide to students as a runnable R file, students can run a four-step model, and interact with and interpret the outputs. This gives them firsthand experience with a demand model, which will promote improved communications between model output consumers and model developers once the students enter the workforce.

Insufficient accounting for induced demand—the phenomenon of roadway expansion leading to additional demand [@downs_still_2004]—is a common criticism of four-step models. This is a particular concern among planning students. My First Four-Step Model is worse even than most production travel models; it does not account for induced demand at all. While most models would use estimates of network travel time and travel cost in the distribution and mode choice, and thus be at least somewhat sensitive to changes in the network, My First Four-Step Model relies entirely on crow-flies distances.

My First Four-Step Model will never be appropriate for production travel demand modeling. It is also not appropriate as a sole teaching tool for students who will ultimately become modelers. However, it is useful as a first exercise even in courses that focus only on demand modeling, where students can have a chance to work with a simple model before diving into the more complex theories and software that are necessary for a detailed education in this area.

## Data availaility statement

Some or all data, models, or code generated or used during the study are available in a repository online.

- Models and code are available on Github: <https://github.com/mattwigway/MyFirstFourStepModel>
- Street network data are available from OpenStreetMap: <https://slice.openstreetmap.us>
- Demographic data are available from the US Census Bureau, at several locations:
  - Residential locations: through the `tidycensus` package [@tidycensus]
  - Job locations: LEHD LODES program [@LODES]
  - Seed matrix: Integrated Public Use Microdata Sample [@ruggles_ipums_2024]
- NHTS survey data [@NHTS_2017]
- Puget Sound Survey Data [@PSRC_Household_Travel_Survey]
- Student grade data are not publicly available to protect privacy

## Acknowledgements

Road network data in @fig-generation–@fig-widen © OpenStreetMap contributors. An earlier version of this work was presented at the Transportation Research Board Annual Meeting [@bhagat-conway_my_2025].

## Statement on artificial intelligence

No generative AI tools were used in this research.

## References

::: {#refs}
:::
